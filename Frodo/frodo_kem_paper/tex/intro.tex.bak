\section{Introduction}

Secure communications channels have become essential for the transmission of
sensitive information over the Internet or between embedded devices, requiring
protocols such as public-key encryption and digital signatures. Furthermore, these
requirements for data security and privacy are becoming more important as the number of connected devices increases, due to the popularity of the Internet of Things.

So far, practitioners have relied on cryptography based on the hardness of the
factoring assumption (RSA) or the discrete logarithm problem (ECC).
However, should a quantum computer be realized, the hardness of these related
problems will be seriously weakened. This issue not only affects future communications
but also secure messages sent today, which could be intercepted and
stored, then decrypted by a device built a decade from now. Preparing for this is
therefore paramount, and hence quantum-safe alternatives are needed to provide
long-term security. The National Institute for Standards and Technology (NIST) has called for quantum-resistant cryptographic algorithms for new public-key cryptography standards, similar to previous AES and SHA-3 competitions \cite{chen2016report}.

Lattice-based cryptography is one of the most promising replacements for classical cryptography, accounting for more than 40\% of the submissions to the NIST post-quantum standardization effort. This is due to many reasons, one of which is that most of the computations required involves very simple and parallelizable operations like integer multiplication, addition, and modular reduction. Unlike RSA-based schemes, which involve very hard computations like modular exponentiation. Moreover, lattice-based cryptography benefits from the strong security notion of worst-case to average-case hardness, meaning average-case instances are at least as hard as worst-case instances of related (much smaller) lattice problems \cite{DBLP:conf/crypto/MicciancioP13}.

In recent years, there has been tremendous growth in lattice-based cryptography as a research field. As a result, concepts such as functional encryption \cite{DBLP:conf/tcc/BonehSW11}, identity-based encryption \cite{DBLP:conf/asiacrypt/DucasLP14}, attribute-based encryption \cite{DBLP:conf/tcc/Boyen13}, and fully homomorphic encryption \cite{gentry2009fully} are now available. On the practical front, some constructions of public-key encryption schemes and digital signature schemes based on lattice problems are now more practical than traditional schemes based on RSA \cite{DBLP:journals/tecs/HowePOOG15}. Lyubashevsky \cite{DBLP:conf/pkc/Lyubashevsky08,DBLP:conf/eurocrypt/LyubashevskyPR10} proposed a new class of lattices, \textit{ideal} lattices, that provide higher efficiency than standard lattices as schemes based upon ideal lattices require less memory and have a better performance than schemes based on standard lattices. Therefore the majority of research targeting practical evaluations of lattice-based cryptography have focused on ideal lattices \cite{DBLP:conf/ches/GottertFSBH12, DBLP:conf/pqcrypto/GuneysuOPS13, ducas2013lattice, DBLP:conf/ches/RoyVMCV14,DBLP:journals/iacr/0001SRGKV15, DBLP:conf/cans/LongaN16,rtesla}. This improvement in efficiency is possible due to an introduced structure in the underlying lattice in these constructions. While the main operation in standard lattices is matrix-vector (or matrix-matrix) multiplication, the complexity is reduced to polynomial multiplication in ideal lattice-based cryptography. However, to this day it is not clear whether a future (quantum) attack might be able to exploit this additional structure, introduced in ideal lattices, in order to break the cryptosystem. Standard lattices do not suffer from this potential weakness and can therefore be considered the more conservative choice, as recommended by Howe et al. \cite{DBLP:conf/dac/HoweMORGB16} and the EU Horizon 2020 project PQCRYPTO \cite{initial}. The EU Horizon 2020 project SAFEcrypto also investigate the use of (standard) lattice-based cryptography in hardware, specifically for conservative use cases such as satellite communications.

The \textsf{FrodoCCS} key exchange scheme by Bos et al. \cite{DBLP:conf/ccs/BosCDMNNRS16} is designed to offer exactly this -- trading some efficiency for high security trust in the post-quantum era. Another design rationale for \textsf{FrodoCCS} is for simplicity, and this is seen in its use of basic operations like addition and multiplication. The parameter sets are much more flexible and easier to scale in comparison to \textsf{NewHopeUSENIX} \cite{DBLP:conf/uss/AlkimDPS16,NISTPQC-R1:NewHope17}, which have a number of restrictions in order to use NTT polynomial multiplication, and can target more security levels which essentially scale linearly.

A modified version of \textsf{FrodoCCS} \cite{DBLP:conf/ccs/BosCDMNNRS16} has been submitted to the NIST standardization process \cite{frodo-nist}, proposed as a key encapsulation mechanism (KEM), named \textsf{FrodoKEM}. The submission comes with a reference implementation and a vectorized implementation for high-end Intel CPUs. However, to date there has been no research into the feasibility of \textsf{FrodoKEM} on embedded devices. In this paper, we want to bridge the gap between the lack of practical evaluations of standard lattice-based cryptography and the need for long-term security solutions for the Internet of Things. This task is especially challenging considering the conservative parameters that were a design rationale of \textsf{FrodoKEM}. As embedded devices, like FPGAs and microcontrollers, usually have very limited memory, we have to pay special attention to minimize the memory consumption of our implementations while not deteriorating the performance too much to not overexert the limited computing capabilities of these platforms.

%This presentation focuses on \emph{practical} lattice-based cryptography, with an inclination towards hardware architectures and optimisations. The talk will survey the trends of past implementations of lattice-based designs, discuss the current state-of-the-art, and propose future research avenues that need to be addressed if lattice-based cryptography is to be integrated in real-world systems.

%Previous designs have mainly focused on highly optimised encryption and digital signatures schemes, as well as the modules used ubiquitously within the area such as number theoretic transform (NTT) multipliers and discrete Gaussian samplers. We will go in depth regarding the differences between these implementations and discuss the importance of each module with respect to the overall performance.

%With the NIST post-quantum standardisation project in its first stage, the main focus of cryptographers today is to evaluate the competing schemes with respect to cryptanalysis. Moreover, these schemes have (and will) come under scrutiny with respect to side-channel analysis (SCA). These current trends will also be discussed in the talk, outlining the potential weaknesses in lattice-based cryptosystems and the fixes proposed for them.

%This presentation will also touch on the importance of hardware designs, in particular on field-programmable gate arrays (FPGAs), for motivation. Recently, there has been a major shift towards FPGA use in cloud services, since FPGAs are able to contribute significant amounts of computing power at a lower cost in comparison to central processing units (CPUs). Additionally, FPGA devices are also being used for encryption and compression \cite{microsoftFPGA}, and hence will become a key component in the future in the context of IoT (such as vehicle-to-everything communications) where protection against quantum computers may be extremely vital.


\subsection{Related Work}

To the best of the authors' knowledge, there has been no previous research on evaluating \textsf{FrodoKEM} on embedded devices. There has been some evaluation of standard lattice-based cryptography on constrained devices, however this area of research is very limited due to the high demand of resources these schemes inherently require. Howe et al. \cite{DBLP:conf/dac/HoweMORGB16} present an implementation of the standard lattice-based encryption scheme, proposed by Lindner and Peikert \cite{DBLP:conf/ctrsa/LindnerP11}, on FPGA. The encryption scheme is based on the Learning with Errors problem, which is the same hardness problem used for security in \textsf{FrodoKEM}. However, the parameters and the operations are significantly different. Most notable, LWE encryption just requires vector-matrix multiplication, while \textsf{FrodoKEM} requires matrix-matrix multiplication. Another lattice-based submission to the NIST standardization is the \textsf{NewHopeNIST} key exchange \cite{DBLP:conf/uss/AlkimDPS16,NISTPQC-R1:NewHope17}. In contrast to \textsf{FrodoKEM}, \textsf{NewHopeNIST} is based on ideal lattices and therefore its implementations are much more efficient. The works by Kuo et al. \cite{cryptoeprint:2017:690} and Oder and G{\"u}neysu \cite{oder2017implementing} implement the scheme on FPGAs and Alkim et al. \cite{alkim2016newhope} present a microcontroller implementation.

Key exchange schemes based on other classes of mathematical problems other than lattices have been implemented on embedded devices as well. Koziel et al. \cite{DBLP:conf/indocrypt/KozielAK16} have implemented a key exchange scheme based on supersingular isogenies for FPGAs. Also, von Maurich et al. \cite{DBLP:conf/pqcrypto/MaurichHG16} implemented a key encapsulation scheme based on linear codes for ARM microcontrollers. There are also numerous implementations of key exchange schemes based on elliptic curves \cite{DBLP:conf/tsp/RasoMFPK15, DBLP:conf/ccs/0001SHHG15, DBLP:journals/dcc/DullHHHPSS15}. But as Shor's algorithm \cite{DBLP:conf/focs/Shor94} can efficiently solve the elliptic curve discrete logarithm problem, those scheme are not considered secure in a post-quantum age.

%TODO maybe mention the differences between key exchange and KEM.

\subsection{Contribution}
In this work, we present the first implementations of \textsf{FrodoKEM} targeting constrained devices in hardware and software, and demonstrate that the conservative \textsf{FrodoKEM} scheme is a suitable option for embedded devices.
 
\begin{itemize}
\item Our FPGA design targets a balance between area consumption and throughput performance. This design choice is seen in the limited use of one multiplier module and minimal use of memory. A LWE multiplication core is proposed which is constantly reused for the main operations of the scheme, where the remaining operations are computed in parallel, essentially making multiplication the critical path of the design. The runtime of this depends exactly on the number of inputs, meaning all designs run in constant time. Most designs utilize less than 2000 FPGA slices and can output 51 operations per second (20 ms) for the main parameter set and 22 operations per second (45 ms) for the higher parameter set.

\item Our ARM implementations make use of an optimized memory allocation that makes the implementation small enough to fit on embedded microcontrollers. We developed an assembly multiplication routine to speed up our implementation, realizing a performance that fits the requirements of common use-cases. The implementation for 128-bit security takes 266 ms for key generation, 284 ms for encapsulation, 286 ms for decapsulation, resulting in a total execution time of 836 ms for a full run of the protocol. To allow independent verification of our results and further improvements, our source code will be made publicly available with publication of this work.
\end{itemize}

Our results show that even one of the more conservative lattice-based submissions to the NIST standardization process (i.e., no ring structure as in ideal lattices) can be run efficiently on constrained devices. Our implementations are fully compliant with the official specification of \textsf{FrodoKEM} to ensure compatibility with implementations on other platforms. The intention of our work is to contribute to the NIST standardization process by demonstrating the practicability of the promising post-quantum candidate \textsf{FrodoKEM}.
